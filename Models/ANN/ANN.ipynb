{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd21754-6f31-4e2c-9fff-df5f310b900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55022c85-1ac5-4980-99e3-d9bb1864ef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('preprocessedDataset_standarized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "352ca5a0-f088-43ff-b1f1-cea21657d865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.716469</td>\n",
       "      <td>-0.832395</td>\n",
       "      <td>0.267497</td>\n",
       "      <td>0.176431</td>\n",
       "      <td>-0.719213</td>\n",
       "      <td>0.317124</td>\n",
       "      <td>-0.056915</td>\n",
       "      <td>-0.673342</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.716469</td>\n",
       "      <td>2.323345</td>\n",
       "      <td>-0.220182</td>\n",
       "      <td>-0.225344</td>\n",
       "      <td>-0.719213</td>\n",
       "      <td>2.824550</td>\n",
       "      <td>-0.986927</td>\n",
       "      <td>-0.461754</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.716469</td>\n",
       "      <td>-0.053084</td>\n",
       "      <td>-0.179562</td>\n",
       "      <td>-0.214660</td>\n",
       "      <td>-0.719213</td>\n",
       "      <td>1.570837</td>\n",
       "      <td>1.167900</td>\n",
       "      <td>2.587284</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.716469</td>\n",
       "      <td>0.668484</td>\n",
       "      <td>-0.208706</td>\n",
       "      <td>0.230020</td>\n",
       "      <td>-0.719213</td>\n",
       "      <td>0.317124</td>\n",
       "      <td>-0.044897</td>\n",
       "      <td>-0.479771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.716469</td>\n",
       "      <td>2.694872</td>\n",
       "      <td>-0.243520</td>\n",
       "      <td>-0.218232</td>\n",
       "      <td>-0.719213</td>\n",
       "      <td>0.317124</td>\n",
       "      <td>0.152121</td>\n",
       "      <td>-0.499124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.716469 -0.832395  0.267497  0.176431 -0.719213  0.317124 -0.056915   \n",
       "1 -0.716469  2.323345 -0.220182 -0.225344 -0.719213  2.824550 -0.986927   \n",
       "2 -0.716469 -0.053084 -0.179562 -0.214660 -0.719213  1.570837  1.167900   \n",
       "3 -0.716469  0.668484 -0.208706  0.230020 -0.719213  0.317124 -0.044897   \n",
       "4 -0.716469  2.694872 -0.243520 -0.218232 -0.719213  0.317124  0.152121   \n",
       "\n",
       "          7  Target  \n",
       "0 -0.673342       0  \n",
       "1 -0.461754       0  \n",
       "2  2.587284       1  \n",
       "3 -0.479771       0  \n",
       "4 -0.499124       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44bec0c7-dcf5-4cf2-9690-22cdd52b1c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'Class' is your target variable\n",
    "X = data.drop('Target', axis=1)  # Features\n",
    "y = data['Target']  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83f22a42-9417-4d0c-8719-79b9813d695d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160727, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "464977e1-726c-46dc-93b5-17241f94e8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160727,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60e5aa81-1e22-48c0-8c34-8fd404ac58cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbbb7c0e-55f5-4c07-b568-7028c6772aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "213dde14-bca9-4a9c-8953-6e8beff7f8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ANACONDA\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the ANN model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Input layer and first hidden layer\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))  # 64 neurons\n",
    "model.add(layers.Dropout(0.5))  # Dropout for regularization\n",
    "\n",
    "# Second hidden layer\n",
    "model.add(layers.Dense(32, activation='relu'))  # 32 neurons\n",
    "\n",
    "# Output layer\n",
    "model.add(layers.Dense(1, activation='sigmoid'))  # Binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "528dd739-2667-478d-b5e4-da1369f204d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',                     # Adam optimizer\n",
    "    loss='binary_crossentropy',           # Loss function for binary classification\n",
    "    metrics=['accuracy']                  # Metrics to evaluate\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f00cf32-8220-48d4-b9fe-5631df45d4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9319 - loss: 0.2027 - val_accuracy: 0.9492 - val_loss: 0.1469\n",
      "Epoch 2/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9448 - loss: 0.1543 - val_accuracy: 0.9492 - val_loss: 0.1460\n",
      "Epoch 3/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9432 - loss: 0.1568 - val_accuracy: 0.9489 - val_loss: 0.1465\n",
      "Epoch 4/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9467 - loss: 0.1502 - val_accuracy: 0.9496 - val_loss: 0.1447\n",
      "Epoch 5/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9436 - loss: 0.1547 - val_accuracy: 0.9470 - val_loss: 0.1453\n",
      "Epoch 6/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9460 - loss: 0.1505 - val_accuracy: 0.9473 - val_loss: 0.1442\n",
      "Epoch 7/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9459 - loss: 0.1483 - val_accuracy: 0.9496 - val_loss: 0.1417\n",
      "Epoch 8/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9453 - loss: 0.1515 - val_accuracy: 0.9475 - val_loss: 0.1425\n",
      "Epoch 9/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9464 - loss: 0.1484 - val_accuracy: 0.9455 - val_loss: 0.1445\n",
      "Epoch 10/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9472 - loss: 0.1447 - val_accuracy: 0.9484 - val_loss: 0.1407\n",
      "Epoch 11/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9462 - loss: 0.1478 - val_accuracy: 0.9484 - val_loss: 0.1409\n",
      "Epoch 12/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9475 - loss: 0.1444 - val_accuracy: 0.9484 - val_loss: 0.1399\n",
      "Epoch 13/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9478 - loss: 0.1429 - val_accuracy: 0.9498 - val_loss: 0.1393\n",
      "Epoch 14/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9464 - loss: 0.1469 - val_accuracy: 0.9493 - val_loss: 0.1394\n",
      "Epoch 15/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9472 - loss: 0.1450 - val_accuracy: 0.9454 - val_loss: 0.1410\n",
      "Epoch 16/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9474 - loss: 0.1427 - val_accuracy: 0.9487 - val_loss: 0.1380\n",
      "Epoch 17/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9454 - loss: 0.1469 - val_accuracy: 0.9491 - val_loss: 0.1379\n",
      "Epoch 18/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9486 - loss: 0.1412 - val_accuracy: 0.9498 - val_loss: 0.1388\n",
      "Epoch 19/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9472 - loss: 0.1430 - val_accuracy: 0.9475 - val_loss: 0.1394\n",
      "Epoch 20/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9474 - loss: 0.1427 - val_accuracy: 0.9495 - val_loss: 0.1374\n",
      "Epoch 21/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9470 - loss: 0.1448 - val_accuracy: 0.9490 - val_loss: 0.1376\n",
      "Epoch 22/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9464 - loss: 0.1437 - val_accuracy: 0.9503 - val_loss: 0.1363\n",
      "Epoch 23/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9469 - loss: 0.1434 - val_accuracy: 0.9495 - val_loss: 0.1365\n",
      "Epoch 24/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9461 - loss: 0.1426 - val_accuracy: 0.9462 - val_loss: 0.1389\n",
      "Epoch 25/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9481 - loss: 0.1411 - val_accuracy: 0.9505 - val_loss: 0.1358\n",
      "Epoch 26/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9475 - loss: 0.1404 - val_accuracy: 0.9491 - val_loss: 0.1356\n",
      "Epoch 27/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9487 - loss: 0.1404 - val_accuracy: 0.9492 - val_loss: 0.1357\n",
      "Epoch 28/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9478 - loss: 0.1403 - val_accuracy: 0.9501 - val_loss: 0.1361\n",
      "Epoch 29/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9474 - loss: 0.1418 - val_accuracy: 0.9496 - val_loss: 0.1364\n",
      "Epoch 30/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9473 - loss: 0.1392 - val_accuracy: 0.9501 - val_loss: 0.1351\n",
      "Epoch 31/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9473 - loss: 0.1409 - val_accuracy: 0.9479 - val_loss: 0.1373\n",
      "Epoch 32/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9462 - loss: 0.1423 - val_accuracy: 0.9477 - val_loss: 0.1371\n",
      "Epoch 33/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9470 - loss: 0.1426 - val_accuracy: 0.9494 - val_loss: 0.1357\n",
      "Epoch 34/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9466 - loss: 0.1428 - val_accuracy: 0.9490 - val_loss: 0.1361\n",
      "Epoch 35/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9476 - loss: 0.1413 - val_accuracy: 0.9478 - val_loss: 0.1364\n",
      "Epoch 36/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9464 - loss: 0.1415 - val_accuracy: 0.9481 - val_loss: 0.1360\n",
      "Epoch 37/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9468 - loss: 0.1413 - val_accuracy: 0.9507 - val_loss: 0.1346\n",
      "Epoch 38/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9467 - loss: 0.1415 - val_accuracy: 0.9472 - val_loss: 0.1368\n",
      "Epoch 39/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9477 - loss: 0.1391 - val_accuracy: 0.9507 - val_loss: 0.1353\n",
      "Epoch 40/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9477 - loss: 0.1399 - val_accuracy: 0.9502 - val_loss: 0.1351\n",
      "Epoch 41/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9483 - loss: 0.1397 - val_accuracy: 0.9491 - val_loss: 0.1360\n",
      "Epoch 42/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9467 - loss: 0.1409 - val_accuracy: 0.9511 - val_loss: 0.1340\n",
      "Epoch 43/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9479 - loss: 0.1404 - val_accuracy: 0.9500 - val_loss: 0.1341\n",
      "Epoch 44/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9472 - loss: 0.1406 - val_accuracy: 0.9489 - val_loss: 0.1360\n",
      "Epoch 45/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9474 - loss: 0.1411 - val_accuracy: 0.9499 - val_loss: 0.1355\n",
      "Epoch 46/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9468 - loss: 0.1432 - val_accuracy: 0.9497 - val_loss: 0.1346\n",
      "Epoch 47/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9482 - loss: 0.1401 - val_accuracy: 0.9505 - val_loss: 0.1354\n",
      "Epoch 48/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9485 - loss: 0.1385 - val_accuracy: 0.9494 - val_loss: 0.1364\n",
      "Epoch 49/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9470 - loss: 0.1408 - val_accuracy: 0.9490 - val_loss: 0.1356\n",
      "Epoch 50/50\n",
      "\u001b[1m3215/3215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9477 - loss: 0.1392 - val_accuracy: 0.9475 - val_loss: 0.1366\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88f754e0-9e70-4327-8f85-35fc81d51267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1005/1005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")  # Convert probabilities to binary output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "195b4142-b1f6-4c5d-9caa-a07bbe663011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9b75066-8e31-4e54-9b9e-ab38334b3c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9466\n"
     ]
    }
   ],
   "source": [
    "#  Evaluate the model\n",
    "# Accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6def850-fcd7-4e32-a06f-ef3295d71b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[29938   103]\n",
      " [ 1612   493]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     30041\n",
      "           1       0.83      0.23      0.37      2105\n",
      "\n",
      "    accuracy                           0.95     32146\n",
      "   macro avg       0.89      0.62      0.67     32146\n",
      "weighted avg       0.94      0.95      0.93     32146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "623fdbcc-6043-41f6-80fb-9666f6cde8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "[[0.]]\n",
      "Accident not gonna happen\n"
     ]
    }
   ],
   "source": [
    "input_data=(3,4823,4000,15396,3,1,0.046471591,0.108695652)\n",
    "#change to numpy array\n",
    "input_data_as_numpy_array = np.asarray(input_data)\n",
    "\n",
    "#reshape the array\n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
    "\n",
    "#standardize the data\n",
    "\n",
    "prediction = model.predict(input_data_reshaped)\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0]==0):\n",
    "    print('Accident not gonna happen')\n",
    "else:\n",
    "    print('Accident gonna happen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5f28008-4db8-4a93-a492-2aef22f8246f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ANACONDA\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - accuracy: 0.8468 - loss: 0.3575 - val_accuracy: 0.8412 - val_loss: 0.4040\n",
      "Epoch 2/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8637 - loss: 0.3159 - val_accuracy: 0.8173 - val_loss: 0.4715\n",
      "Epoch 3/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.8656 - loss: 0.3078 - val_accuracy: 0.8602 - val_loss: 0.3942\n",
      "Epoch 4/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8676 - loss: 0.3026 - val_accuracy: 0.8069 - val_loss: 0.4377\n",
      "Epoch 5/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8686 - loss: 0.2999 - val_accuracy: 0.8565 - val_loss: 0.3696\n",
      "Epoch 6/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.8703 - loss: 0.2950 - val_accuracy: 0.8348 - val_loss: 0.4484\n",
      "Epoch 7/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8733 - loss: 0.2904 - val_accuracy: 0.8567 - val_loss: 0.3559\n",
      "Epoch 8/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.8744 - loss: 0.2883 - val_accuracy: 0.8806 - val_loss: 0.3391\n",
      "Epoch 9/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.8769 - loss: 0.2844 - val_accuracy: 0.8497 - val_loss: 0.4132\n",
      "Epoch 10/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8763 - loss: 0.2841 - val_accuracy: 0.8546 - val_loss: 0.3899\n",
      "Epoch 11/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8793 - loss: 0.2792 - val_accuracy: 0.8790 - val_loss: 0.3446\n",
      "Epoch 12/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.8805 - loss: 0.2778 - val_accuracy: 0.8868 - val_loss: 0.3365\n",
      "Epoch 13/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8795 - loss: 0.2764 - val_accuracy: 0.8614 - val_loss: 0.3854\n",
      "Epoch 14/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.8815 - loss: 0.2736 - val_accuracy: 0.8918 - val_loss: 0.3260\n",
      "Epoch 15/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8822 - loss: 0.2722 - val_accuracy: 0.8728 - val_loss: 0.3646\n",
      "Epoch 16/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8826 - loss: 0.2697 - val_accuracy: 0.9014 - val_loss: 0.3177\n",
      "Epoch 17/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.8862 - loss: 0.2650 - val_accuracy: 0.8654 - val_loss: 0.3618\n",
      "Epoch 18/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8872 - loss: 0.2636 - val_accuracy: 0.8687 - val_loss: 0.3490\n",
      "Epoch 19/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8854 - loss: 0.2636 - val_accuracy: 0.8682 - val_loss: 0.3648\n",
      "Epoch 20/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8848 - loss: 0.2640 - val_accuracy: 0.9077 - val_loss: 0.2760\n",
      "Epoch 21/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8881 - loss: 0.2594 - val_accuracy: 0.8690 - val_loss: 0.3562\n",
      "Epoch 22/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8881 - loss: 0.2603 - val_accuracy: 0.8821 - val_loss: 0.3327\n",
      "Epoch 23/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.8895 - loss: 0.2571 - val_accuracy: 0.8633 - val_loss: 0.3829\n",
      "Epoch 24/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8910 - loss: 0.2540 - val_accuracy: 0.8625 - val_loss: 0.3691\n",
      "Epoch 25/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8912 - loss: 0.2542 - val_accuracy: 0.8738 - val_loss: 0.3504\n",
      "Epoch 26/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - accuracy: 0.8913 - loss: 0.2522 - val_accuracy: 0.8960 - val_loss: 0.3151\n",
      "Epoch 27/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.8906 - loss: 0.2532 - val_accuracy: 0.8713 - val_loss: 0.3426\n",
      "Epoch 28/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.8939 - loss: 0.2485 - val_accuracy: 0.8801 - val_loss: 0.3457\n",
      "Epoch 29/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.8916 - loss: 0.2512 - val_accuracy: 0.8889 - val_loss: 0.3122\n",
      "Epoch 30/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.8925 - loss: 0.2498 - val_accuracy: 0.9045 - val_loss: 0.2746\n",
      "Epoch 31/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.8938 - loss: 0.2477 - val_accuracy: 0.8817 - val_loss: 0.3411\n",
      "Epoch 32/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.8939 - loss: 0.2474 - val_accuracy: 0.8783 - val_loss: 0.3349\n",
      "Epoch 33/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.8952 - loss: 0.2447 - val_accuracy: 0.8770 - val_loss: 0.3358\n",
      "Epoch 34/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.8953 - loss: 0.2447 - val_accuracy: 0.8808 - val_loss: 0.3499\n",
      "Epoch 35/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.8974 - loss: 0.2418 - val_accuracy: 0.9038 - val_loss: 0.2863\n",
      "Epoch 36/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.8975 - loss: 0.2392 - val_accuracy: 0.8952 - val_loss: 0.3046\n",
      "Epoch 37/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.8965 - loss: 0.2420 - val_accuracy: 0.8932 - val_loss: 0.3015\n",
      "Epoch 38/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.8968 - loss: 0.2418 - val_accuracy: 0.8980 - val_loss: 0.3078\n",
      "Epoch 39/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.8984 - loss: 0.2389 - val_accuracy: 0.9002 - val_loss: 0.3009\n",
      "Epoch 40/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.8975 - loss: 0.2379 - val_accuracy: 0.8948 - val_loss: 0.3101\n",
      "Epoch 41/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.8991 - loss: 0.2378 - val_accuracy: 0.9050 - val_loss: 0.2731\n",
      "Epoch 42/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.8991 - loss: 0.2364 - val_accuracy: 0.8923 - val_loss: 0.3092\n",
      "Epoch 43/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9003 - loss: 0.2351 - val_accuracy: 0.8948 - val_loss: 0.3005\n",
      "Epoch 44/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.8998 - loss: 0.2356 - val_accuracy: 0.9187 - val_loss: 0.2557\n",
      "Epoch 45/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.8999 - loss: 0.2368 - val_accuracy: 0.8697 - val_loss: 0.3454\n",
      "Epoch 46/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9006 - loss: 0.2337 - val_accuracy: 0.8991 - val_loss: 0.2906\n",
      "Epoch 47/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9018 - loss: 0.2319 - val_accuracy: 0.8891 - val_loss: 0.3144\n",
      "Epoch 48/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9019 - loss: 0.2320 - val_accuracy: 0.8904 - val_loss: 0.3162\n",
      "Epoch 49/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9023 - loss: 0.2304 - val_accuracy: 0.9016 - val_loss: 0.3078\n",
      "Epoch 50/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9022 - loss: 0.2312 - val_accuracy: 0.8861 - val_loss: 0.3132\n",
      "Epoch 51/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9033 - loss: 0.2284 - val_accuracy: 0.8914 - val_loss: 0.3206\n",
      "Epoch 52/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9039 - loss: 0.2276 - val_accuracy: 0.9006 - val_loss: 0.2935\n",
      "Epoch 53/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9041 - loss: 0.2269 - val_accuracy: 0.8971 - val_loss: 0.2939\n",
      "Epoch 54/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9041 - loss: 0.2262 - val_accuracy: 0.9063 - val_loss: 0.2785\n",
      "Epoch 55/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9042 - loss: 0.2267 - val_accuracy: 0.9033 - val_loss: 0.2723\n",
      "Epoch 56/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.2259 - val_accuracy: 0.9111 - val_loss: 0.2741\n",
      "Epoch 57/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9042 - loss: 0.2255 - val_accuracy: 0.8663 - val_loss: 0.3595\n",
      "Epoch 58/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9049 - loss: 0.2247 - val_accuracy: 0.9122 - val_loss: 0.2731\n",
      "Epoch 59/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9058 - loss: 0.2229 - val_accuracy: 0.9095 - val_loss: 0.2706\n",
      "Epoch 60/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9054 - loss: 0.2246 - val_accuracy: 0.8954 - val_loss: 0.3051\n",
      "Epoch 61/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9063 - loss: 0.2230 - val_accuracy: 0.9161 - val_loss: 0.2539\n",
      "Epoch 62/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9063 - loss: 0.2227 - val_accuracy: 0.9192 - val_loss: 0.2609\n",
      "Epoch 63/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9064 - loss: 0.2228 - val_accuracy: 0.8944 - val_loss: 0.3047\n",
      "Epoch 64/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9063 - loss: 0.2215 - val_accuracy: 0.9175 - val_loss: 0.2498\n",
      "Epoch 65/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9065 - loss: 0.2217 - val_accuracy: 0.9070 - val_loss: 0.2815\n",
      "Epoch 66/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.2201 - val_accuracy: 0.9051 - val_loss: 0.2829\n",
      "Epoch 67/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.9064 - loss: 0.2216 - val_accuracy: 0.9129 - val_loss: 0.2588\n",
      "Epoch 68/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.2193 - val_accuracy: 0.9064 - val_loss: 0.2957\n",
      "Epoch 69/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.2193 - val_accuracy: 0.8931 - val_loss: 0.3100\n",
      "Epoch 70/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9073 - loss: 0.2195 - val_accuracy: 0.8907 - val_loss: 0.3052\n",
      "Epoch 71/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.2179 - val_accuracy: 0.8919 - val_loss: 0.3331\n",
      "Epoch 72/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.2180 - val_accuracy: 0.9018 - val_loss: 0.2994\n",
      "Epoch 73/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.2181 - val_accuracy: 0.9006 - val_loss: 0.2853\n",
      "Epoch 74/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2163 - val_accuracy: 0.9218 - val_loss: 0.2557\n",
      "Epoch 75/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2134 - val_accuracy: 0.8748 - val_loss: 0.3570\n",
      "Epoch 76/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9084 - loss: 0.2161 - val_accuracy: 0.9021 - val_loss: 0.2999\n",
      "Epoch 77/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9094 - loss: 0.2157 - val_accuracy: 0.9036 - val_loss: 0.2802\n",
      "Epoch 78/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2151 - val_accuracy: 0.9074 - val_loss: 0.2915\n",
      "Epoch 79/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.2160 - val_accuracy: 0.9154 - val_loss: 0.2680\n",
      "Epoch 80/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.2165 - val_accuracy: 0.9028 - val_loss: 0.2952\n",
      "Epoch 81/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2141 - val_accuracy: 0.8990 - val_loss: 0.2918\n",
      "Epoch 82/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2109 - val_accuracy: 0.8949 - val_loss: 0.3018\n",
      "Epoch 83/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2126 - val_accuracy: 0.9174 - val_loss: 0.2614\n",
      "Epoch 84/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2120 - val_accuracy: 0.8830 - val_loss: 0.3233\n",
      "Epoch 85/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2120 - val_accuracy: 0.9171 - val_loss: 0.2550\n",
      "Epoch 86/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9113 - loss: 0.2123 - val_accuracy: 0.8907 - val_loss: 0.3222\n",
      "Epoch 87/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2118 - val_accuracy: 0.9018 - val_loss: 0.2856\n",
      "Epoch 88/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.9125 - loss: 0.2105 - val_accuracy: 0.8720 - val_loss: 0.3444\n",
      "Epoch 89/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2108 - val_accuracy: 0.8987 - val_loss: 0.3038\n",
      "Epoch 90/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2119 - val_accuracy: 0.9061 - val_loss: 0.2795\n",
      "Epoch 91/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2099 - val_accuracy: 0.9092 - val_loss: 0.2786\n",
      "Epoch 92/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2085 - val_accuracy: 0.8873 - val_loss: 0.3134\n",
      "Epoch 93/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2100 - val_accuracy: 0.9166 - val_loss: 0.2586\n",
      "Epoch 94/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2093 - val_accuracy: 0.9184 - val_loss: 0.2551\n",
      "Epoch 95/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2078 - val_accuracy: 0.8941 - val_loss: 0.3105\n",
      "Epoch 96/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2074 - val_accuracy: 0.9001 - val_loss: 0.2946\n",
      "Epoch 97/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2086 - val_accuracy: 0.9121 - val_loss: 0.2588\n",
      "Epoch 98/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2073 - val_accuracy: 0.9131 - val_loss: 0.2676\n",
      "Epoch 99/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2061 - val_accuracy: 0.9028 - val_loss: 0.2741\n",
      "Epoch 100/100\n",
      "\u001b[1m6009/6009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2096 - val_accuracy: 0.9179 - val_loss: 0.2492\n",
      "\u001b[1m1005/1005\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93     30045\n",
      "           1       0.33      0.73      0.45      2101\n",
      "\n",
      "    accuracy                           0.88     32146\n",
      "   macro avg       0.65      0.81      0.69     32146\n",
      "weighted avg       0.94      0.88      0.90     32146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale your features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Apply SMOTE to handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Build the ANN model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train_resampled.shape[1],)),  # Input layer\n",
    "    layers.Dense(64, activation='relu'),  # Hidden layer\n",
    "    layers.Dense(32, activation='relu'),  # Hidden layer\n",
    "    layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_resampled, y_train_resampled, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs >= 0.5).astype(int)  # Adjust the threshold if needed\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
